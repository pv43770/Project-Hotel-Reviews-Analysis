{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43a7abc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce4491a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6dcbce6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-08 21:02:16.970 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run C:\\Users\\pv437\\anaconda3\\envs\\bot\\lib\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n"
     ]
    }
   ],
   "source": [
    "from nltk import pos_tag, word_tokenize\n",
    "from nltk.corpus import wordnet\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Load the data and preprocess it\n",
    "reviews = pd.read_excel(r'C:\\Users\\pv437\\Desktop\\Data Scince Folder\\Projects\\Project 2\\hotel_reviews.xlsx')\n",
    "df = pd.read_csv(r'C:\\Users\\pv437\\Desktop\\Data Scince Folder\\Projects\\Project 2\\Hotel_Noun.csv')\n",
    "\n",
    "# Use TF-IDF to vectorize the reviews\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform(reviews['Review'])\n",
    "\n",
    "# Function to get the top N most similar reviews based on user input\n",
    "def get_top_similar_reviews(user_input, top_n):\n",
    "    user_vector = vectorizer.transform([user_input])\n",
    "    similarity = cosine_similarity(user_vector, tfidf_matrix).flatten()\n",
    "\n",
    "    # Get the indices of the top reviews\n",
    "    top_indices = similarity.argsort()[-top_n:][::-1]\n",
    "\n",
    "    # Get the actual reviews based on the indices\n",
    "    top_reviews = reviews['Review'].iloc[top_indices].tolist()\n",
    "\n",
    "    return top_reviews\n",
    "\n",
    "# Function to get sentiment\n",
    "def get_sentiment(user_input):\n",
    "    # Initialize the VADER sentiment analyzer\n",
    "    sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "    # Get sentiment polarity scores\n",
    "    sentiment_scores = sia.polarity_scores(user_input)\n",
    "\n",
    "    # Determine sentiment based on the compound score\n",
    "    compound_score = sentiment_scores['compound']\n",
    "\n",
    "    if compound_score >= 0.05:\n",
    "        sentiment = 'Positive'\n",
    "    elif compound_score <= -0.05:\n",
    "        sentiment = 'Negative'\n",
    "    else:\n",
    "        sentiment = 'Neutral'\n",
    "\n",
    "    return sentiment, sentiment_scores\n",
    "\n",
    "# Function to filter non-English words\n",
    "def is_english_word(word):\n",
    "    return word.lower() in wordnet.words()\n",
    "\n",
    "# Function to extract nouns from a sentence\n",
    "def extract_nouns_from_sentence(sentence):\n",
    "    words = word_tokenize(sentence)\n",
    "    tagged_words = pos_tag(words)\n",
    "    nouns = [word for word, pos in tagged_words if pos.startswith('N')]\n",
    "    return set(nouns)\n",
    "\n",
    "# Function to print min and max counts\n",
    "def print_min_max_counts(df):\n",
    "    min_count = df['Count'].min()\n",
    "    max_count = df['Count'].max()\n",
    "\n",
    "    st.write(f\"Minimum Count/Frequency of a Keyword: {min_count}\")\n",
    "    st.write(f\"Maximum Count/Frequency of a Keyword: {max_count}\")\n",
    "\n",
    "# Function to print top N nouns by count\n",
    "def print_top_n_nouns_by_count(df, threshold_count, top_n):\n",
    "    # Filter DataFrame based on the specified threshold count\n",
    "    filtered_df = df[df['Count'] <= threshold_count]\n",
    "\n",
    "    # Sort the filtered DataFrame by the 'Count' column in descending order\n",
    "    df_sorted = filtered_df.sort_values(by='Count', ascending=False)\n",
    "\n",
    "    # Select the top 'n' rows\n",
    "    top_n_nouns = df_sorted.head(top_n)\n",
    "\n",
    "    # Print the results\n",
    "    st.write(f\"Top {top_n} KeyWords with Count/Frequency Close To {threshold_count}:\")\n",
    "    for i, (index, row) in enumerate(top_n_nouns.iterrows(), 1):\n",
    "        st.write(f\"Top {i} KeyWord close to {threshold_count} is : {row['Noun']}, With Count/Frequency is : {row['Count']}\")      \n",
    "\n",
    "# Streamlit App\n",
    "def main():\n",
    "    st.title(\"Sentiment Analysis and Review Similarity App\")\n",
    "\n",
    "    # Sidebar navigation\n",
    "    page = st.sidebar.radio(\"Navigation\", [\"Sentiment Analysis\", \"Top KeyWords\", \"Review Similarity\"])\n",
    "\n",
    "    # Main content based on selected page\n",
    "    if page == \"Sentiment Analysis\":\n",
    "        st.header(\"Sentiment Analysis\")\n",
    "        user_input_sentiment = st.text_area(\"Enter your text for sentiment analysis:\", value=\"\")\n",
    "        \n",
    "        if st.button(\"Submit\") and user_input_sentiment.strip() != \"\":\n",
    "            # Extract nouns from each sentence in the input\n",
    "            sentences = user_input_sentiment.split('.')\n",
    "            all_nouns = set()\n",
    "            words = word_tokenize(user_input_sentiment)\n",
    "\n",
    "            for sentence in sentences:\n",
    "                nouns_in_sentence = extract_nouns_from_sentence(sentence)\n",
    "                all_nouns.update(nouns_in_sentence)\n",
    "            legit_nouns = [noun for noun in all_nouns if is_english_word(noun)]\n",
    "\n",
    "            st.write(f\"Unique Keywords from Review: {legit_nouns}\")\n",
    "\n",
    "            # Continue with sentiment analysis\n",
    "            sentiment, scores = get_sentiment(user_input_sentiment)\n",
    "            st.write(f\"Sentiment: {sentiment}\")\n",
    "            st.write(f\"Sentiment Scores: {scores}\")\n",
    "\n",
    "    elif page == \"Top KeyWords\":\n",
    "        st.header(\"Top KeyWords Based On Counts/Frequency\")\n",
    "        print_min_max_counts(df)\n",
    "        user_input_threshold = int(st.number_input(\"Enter the minimum count or Frequency for KeyWords:\", min_value=0, value=0))\n",
    "        user_input_top_n = int(st.number_input(\"Enter the number for KeyWords you want to display:\", min_value=1, value=1))\n",
    "        \n",
    "        if st.button(\"Submit\") and user_input_threshold != 0 and user_input_top_n != 0:\n",
    "            print_top_n_nouns_by_count(df, user_input_threshold, user_input_top_n)\n",
    "\n",
    "    elif page == \"Review Similarity\":\n",
    "        st.header(\"Review Similarity Based On Keywords\")\n",
    "        user_input_similarity = st.text_area(\"Enter your text for finding similar reviews:\", value=\"\")\n",
    "        num_reviews_similarity = int(st.number_input(\"Enter the number for Similar reviews you want to see:\", min_value=1, value=10))\n",
    "        \n",
    "        if st.button(\"Submit\") and user_input_similarity.strip() != \"\":\n",
    "            # Extract nouns from each sentence in the input\n",
    "            sentences = user_input_similarity.split('.')\n",
    "            all_nouns = set()\n",
    "\n",
    "            for sentence in sentences:\n",
    "                nouns_in_sentence = extract_nouns_from_sentence(sentence)\n",
    "                all_nouns.update(nouns_in_sentence)\n",
    "\n",
    "            st.write(f\"Top {num_reviews_similarity} Similar Reviews:\")\n",
    "            top_reviews = get_top_similar_reviews(user_input_similarity, top_n=num_reviews_similarity)\n",
    "            for i, review in enumerate(top_reviews, 1):\n",
    "                st.write(f\"Top {i} Review:  {review} \\n \\n \")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a66ee95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda475ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7dd3b38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f32bb4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7d043e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d3adfa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
